{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Examining the context of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10.1\n",
    "\n",
    "Create a concordance for the word 'savage' in the novel *Brave New World*. You can find the full text in the 'Corpus' folder. Work with a width of 50 characters (i.e. 25 characters before and 25 characters after this search term)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 10 of 201 matches:\n",
      "e to go to one of the Savage Reservations with him\n",
      "lways wanted to see a Savage Reservation . ' 'But \n",
      "se I do want to see a Savage Reservation . ' * * *\n",
      " they would be in the Savage Reservation . Not mor\n",
      "ad ever been inside a Savage Reservation . As an A\n",
      "e is no escape from a Savage Reservation . ' The w\n",
      "d to the sullen young savage . 'Funny , I expect .\n",
      " more the men 's deep savage affirmation of their \n",
      "heek . 'Turned into a savage , ' she shouted . 'Ha\n",
      "ather ' of this young savage must be . 'Would you \n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.text import Text\n",
    "import os\n",
    "\n",
    "path = os.path.join('Corpus','BraveNewWorld.txt')\n",
    "\n",
    "with open( path , encoding = 'utf-8') as file:\n",
    "    full_text = file.read()\n",
    "\n",
    "tokens = word_tokenize(full_text)\n",
    "novel = Text(tokens)\n",
    "\n",
    "novel.concordance('savage' , width = 50 , lines = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10.2. \n",
    "\n",
    "Create a concordance for the word 'soma' in the novel *Brave New World*. This time, work with a width of 20 words (i.e. 10 words before and 10 words after this search term). Display the first 15 occurrences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 61 ocurrences of the word \"soma\".\n",
      "Here are the first 15 occurrences:\n",
      "\n",
      "\n",
      "that brute Henry Foster you need is a gramme of soma the advantages of Christianity and alcohol none of their defects \n",
      "\n",
      "in the solid substance of their distractions there is always soma delicious soma half a gramme for a a gramme for \n",
      "\n",
      "solid substance of their distractions there is always soma delicious soma half a gramme for a a gramme for a two \n",
      "\n",
      "that he could have got through life without ever touching soma The malice and bad tempers from which other people had \n",
      "\n",
      "do look glum What you need is a gramme of soma Diving into his Benito produced a phial cubic centimetre cures \n",
      "\n",
      "be true his brain I suppose He put away the soma bottle and taking out a packet of stuffed a plug \n",
      "\n",
      "a loud and cheerful company they ate an excellent meal Soma was served with the coffee Lenina took two tablets and \n",
      "\n",
      "half an hour before closing time that second dose of soma had raised a quite impenetrable wall between the actual universe \n",
      "\n",
      "she was and in spite of that second gramme of soma Lenina did not forget to take all the contraceptive precautions \n",
      "\n",
      "T and sat down The service had begun The dedicated soma tablets were placed in the centre of the dinner table \n",
      "\n",
      "centre of the dinner table The loving cup of strawberry soma was passed from hand to hand and with the formula \n",
      "\n",
      "has but begun Again twelve stanzas By this time the soma had begun to work Eyes shone cheeks were flushed the \n",
      "\n",
      "to Lenina friends of whom they met dozens in the soma bar between the wrestling bouts and in spite of his \n",
      "\n",
      "of all she continued in another tone you do take soma when you have these dreadful ideas of yours You forget \n",
      "\n",
      "were back in his rooms Bernard swallowed four tablets of soma at a gulp turned on the radio and television and \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import math\n",
    "import re\n",
    "import os\n",
    "\n",
    "from text_mining import *\n",
    "\n",
    "path = os.path.join('Corpus','BraveNewWorld.txt')\n",
    "\n",
    "with open( path, encoding = 'utf-8') as file:\n",
    "    full_text = file.read()\n",
    "    \n",
    "fragments = concordance_word( full_text , r'soma' , 20)\n",
    "\n",
    "print( f'There are {len(fragments)} ocurrences of the word \"soma\".')\n",
    "\n",
    "number_of_results = 15\n",
    "\n",
    "print( f'Here are the first {number_of_results} occurrences:\\n\\n')\n",
    "for f in fragments[:number_of_results]:\n",
    "    print( f'{f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10.3\n",
    "\n",
    "In *Ullyses*, which words are used most frequently in the vicinity of the word 'father'? Consider 8 words before and 8 words after all the occurrences of this specific name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conmee => 62\n",
      "cowley => 28\n",
      "son => 27\n",
      "said => 18\n",
      "conroy => 11\n",
      "left => 11\n",
      "like => 9\n",
      "house => 9\n",
      "old => 9\n",
      "mother => 9\n",
      "simon => 8\n",
      "john => 8\n",
      "saluted => 8\n",
      "mr => 8\n",
      "walked => 8\n",
      "reverend => 7\n",
      "little => 7\n",
      "thought => 7\n",
      "stephen => 7\n",
      "man => 7\n",
      "time => 7\n",
      "put => 7\n",
      "handed => 6\n",
      "dedalus => 6\n",
      "smiled => 6\n",
      "blessed => 6\n",
      "told => 6\n",
      "father => 6\n",
      "poor => 6\n",
      "bernard => 6\n",
      "thy => 6\n",
      "ghost => 6\n",
      "hamlet => 6\n",
      "go => 5\n",
      "hanlon => 5\n",
      "malachi => 5\n",
      "along => 5\n",
      "road => 5\n",
      "letter => 5\n",
      "flynn => 5\n",
      "name => 5\n",
      "well => 5\n",
      "friend => 5\n",
      "holy => 5\n",
      "knows => 5\n",
      "god => 5\n",
      "gave => 5\n",
      "captain => 4\n",
      "bloom => 4\n",
      "canon => 4\n",
      "hughes => 4\n",
      "forget => 4\n",
      "virag => 4\n",
      "black => 4\n",
      "constable => 4\n",
      "passed => 4\n",
      "corner => 4\n",
      "hat => 4\n",
      "dineen => 4\n",
      "race => 4\n",
      "sir => 4\n",
      "going => 4\n",
      "art => 4\n",
      "would => 4\n",
      "eyes => 4\n",
      "things => 4\n",
      "child => 4\n",
      "first => 4\n",
      "looked => 4\n",
      "laid => 4\n",
      "voice => 4\n",
      "ennis => 3\n",
      "waiting => 3\n",
      "theyre => 3\n",
      "always => 3\n",
      "used => 3\n",
      "bit => 3\n",
      "corrigan => 3\n",
      "church => 3\n",
      "years => 3\n",
      "must => 3\n",
      "respected => 3\n",
      "dolan => 3\n",
      "thinking => 3\n",
      "air => 3\n",
      "dublin => 3\n",
      "saint => 3\n",
      "hope => 3\n",
      "good => 3\n",
      "talking => 3\n",
      "ancient => 3\n",
      "patrick => 3\n",
      "back => 3\n",
      "cried => 3\n",
      "famous => 3\n",
      "ross => 3\n",
      "dilly => 3\n",
      "read => 3\n",
      "help => 3\n",
      "conductor => 3\n",
      "seemed => 3\n",
      "head => 3\n",
      "saw => 3\n",
      "went => 3\n",
      "right => 3\n",
      "north => 3\n",
      "turned => 3\n",
      "street => 3\n",
      "great => 3\n",
      "red => 3\n",
      "bright => 3\n",
      "provincial => 3\n",
      "walking => 3\n",
      "indeed => 3\n",
      "unborn => 3\n",
      "grandfather => 3\n",
      "envy => 3\n",
      "youth => 3\n",
      "decline => 3\n",
      "new => 3\n",
      "wrote => 3\n",
      "says => 3\n",
      "wife => 3\n",
      "forty => 3\n",
      "call => 3\n",
      "might => 3\n",
      "queen => 3\n",
      "one => 3\n",
      "could => 3\n",
      "day => 3\n",
      "walk => 3\n",
      "got => 3\n",
      "coffey => 3\n",
      "dead => 3\n",
      "quay => 3\n",
      "wise => 3\n",
      "floating => 3\n",
      "vaughan => 3\n",
      "hear => 3\n",
      "consubstantial => 3\n",
      "jew => 3\n",
      "shakespeare => 3\n",
      "grandson => 3\n"
     ]
    }
   ],
   "source": [
    "from text_mining import *\n",
    "import os\n",
    "\n",
    "def sortedByValue( dict , ascending = True ):\n",
    "    if ascending: \n",
    "        return {k: v for k, v in sorted(dict.items(), key=lambda item: item[1])}\n",
    "    else:\n",
    "        return {k: v for k, v in reversed( sorted(dict.items(), key=lambda item: item[1]))}\n",
    "\n",
    "path = os.path.join('Corpus','Ullyses.txt')\n",
    "\n",
    "with open( path, encoding = 'utf-8') as file:\n",
    "    full_text = file.read()\n",
    "    \n",
    "nearby_words = collocation( full_text , r'father' , 20)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "nearby_words_sorted = sortedByValue( nearby_words , ascending = False)\n",
    "\n",
    "for word in list( nearby_words_sorted.keys() ):\n",
    "    freq = nearby_words_sorted[word]\n",
    "    if word not in stopwords and freq > 2:\n",
    "        print( f'{word} => {freq}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10.4\n",
    "\n",
    "Find all the sentences in *Ullyses* that contain the words 'book' and 'read'. Make sure that, in these sentences, there are no more than 10 words in between these two words.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whoâ€™ll read the book?\n",
      "They halted by the bier and the priest began to read out of his book with a fluent croak.\n",
      "And she could see far away the lights of the lighthouses so picturesque she would have loved to do with a box of paints because it was easier than to make a man and soon the lamplighter would be going his rounds past the presbyterian church grounds and along by shady Tritonville avenue where the couples walked and lighting the lamp near her window where Reggy Wylie used to turn his freewheel like she read in that book _The Lamplighter_ by Miss Cummins, author of _Mabel Vaughan_ and other tales.\n",
      "and dout the light whereby you read in the Sacred Book for the oil too has run low, and so with a tranquil heart to bed, to rest.\n",
      "One time I could read a book in the dark, manner of speaking.\n"
     ]
    }
   ],
   "source": [
    "from text_mining import *\n",
    "import os\n",
    "\n",
    "\n",
    "path = os.path.join('Corpus','Ullyses.txt')\n",
    "\n",
    "with open( path, encoding = 'utf-8') as file:\n",
    "    full_text = file.read()\n",
    "    \n",
    "cooccurrences = cooccurrence( full_text , 'book' , 'read' , 10 )\n",
    "\n",
    "for fragment in cooccurrences:\n",
    "    print(fragment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
