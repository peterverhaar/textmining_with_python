{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Sentiment analysis is the process of identifying and characterising the emotions or the opinions that are expressed within machine-readable texts. Sentiment analysis applications commonly make use of lists of words that are indicative of specific sentiments. Such lists or lexicons usually specify whether the words refer to negative or to positive emotions. By calculating the frequencies of these affective words, and by examining the contexts in which these words are used, such tools generally aim to calculate specific sentiment scores. \n",
    "\n",
    "The most basic types of sentiment analysis approaches classify text fragments simply as either positive or negative. Valence-based approaches, by contrast, also consider the intensity of the emmotions that are expressed, and aim to calculate more nuanced sentiment scores. \n",
    "\n",
    "This notebook discusses [Vader](https://github.com/cjhutto/vaderSentiment), which is available both as a separate package and as part of Python's NLTK library. Vader stands for the *Valence Aware Dictionary and sEntiment Reasoner*. Vader makes use of [a list of words](https://github.com/cjhutto/vaderSentiment/blob/master/vaderSentiment/vader_lexicon.txt) whose affective connotations have been evaluated manually by human volunteers. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Vader\n",
    "\n",
    "To work with Vader, it obviously needs to be installed first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If, for some reason, you are unable to install the package, you can also try to download the vader lexicon using NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon', quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you managed to install Vader successfully, you should be able to import the `SentimentIntensityAnalyser` object from the vaderSentiment library in your code. \n",
    "\n",
    "In the code below, this object is renamed into `ana`. This object will function as a sentiment analyser. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "#from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "ana = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have downloader Vader via NLTK, you should place a hash before the first line and remove the hash in front of the second command that is given. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment ratings\n",
    "\n",
    "This object `SentimentIntensityAnalyser` object contains a method named `polarity_scores` which can calculate the sentiment scores. The method only demands a string as a parameter. \n",
    "\n",
    "The method returns a dictionary with four keys:\n",
    "\n",
    "* `neg` gives a score for the level of negativity\n",
    "* `neu` assesses the level of neutrality\n",
    "* `pos` assignes a score for the positivity\n",
    "* the `compound` score, finally, is an overall assessment of the sentiments that are expressed. It is the sum of the first three ratings.\n",
    "\n",
    "The first three scores are all on a range in between 0 and 1. The compound score ranges from -1 to +1. \n",
    "\n",
    "Sentiment scores can firstly be requested for individual words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'good'\n",
    "print( f'{word}')\n",
    "\n",
    "scores = ana.polarity_scores(word)\n",
    "for s in scores:\n",
    "    print( f'  {s} => {scores[s]}')\n",
    "    \n",
    "word = 'terrible'\n",
    "print( f'{word}')\n",
    "    \n",
    "scores = ana.polarity_scores(word)\n",
    "for s in scores:\n",
    "    print( f'  {s} => {scores[s]}')\n",
    "    \n",
    "word = 'ordinary'\n",
    "print( f'{word}')\n",
    "    \n",
    "scores = ana.polarity_scores(word)\n",
    "for s in scores:\n",
    "    print( f'  {s} => {scores[s]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiments of sentences\n",
    "\n",
    "The string that you provide as a parameter to the `polarity_scores()` method can also be a full sentence.  \n",
    "\n",
    "When you run the code below, you will see that first sentence is considered to be 44% neutral and 55% positive, resulting in a compound score of 0.8225. \n",
    "\n",
    "The second sentence is given a score of 0.494 for negativity and a score 0.506 on the neutrality scale. The score for positiviy is 0.0. On the whole, the sentence received a negative compund score of -0.5994.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ana.polarity_scores(\"A thing of beauty is a joy forever\")\n",
    "\n",
    "for s in scores:\n",
    "    print( f'{s}: {scores[s]}'  )\n",
    "    \n",
    "print('\\n')\n",
    "    \n",
    "scores = ana.polarity_scores(\"April is the cruellest month\")\n",
    "\n",
    "for s in scores:\n",
    "    print( f'{s}: {scores[s]}'  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context \n",
    "\n",
    "The scores that are genereated by Vader are not simply the summations of the scores from the lexicon. The application also considers the broader contexts of the words in the sentences. Aspects such as interpunction and capitalisation are taken into account as well. \n",
    "\n",
    "Vader assumes, for example, that capitalisation can increase the intensity of an emotion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ana.polarity_scores(\"It was the BEST of times, it was the worst of times.\")\n",
    "\n",
    "print( f'Positive: { scores[\"pos\"] }' )\n",
    "print( f'Negative: { scores[\"neg\"] }' )\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "scores = ana.polarity_scores(\"It was the best of times, it was the worst of times.\")\n",
    "\n",
    "print( f'Positive: { scores[\"pos\"] }' )\n",
    "print( f'Negative: { scores[\"neg\"] }' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intensifiers such as 'very' or 'really' likewise raise the ratings for particular emotions. The same is the case for exclamation marks. Vader also knows that the word 'not' entails a negation and that the value of a positive word following 'not' should in fact be viewed as a negative word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ana.polarity_scores(\"This novel is good.\")\n",
    "print( f'Overall score: { scores[\"compound\"] }' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ana.polarity_scores(\"This novel is very good!\")\n",
    "print( f'Overall score: { scores[\"compound\"] }' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ana.polarity_scores(\"This novel is very GOOD!\")\n",
    "print( f'Overall score: { scores[\"compound\"] }' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ana.polarity_scores(\"This novel is not good.\")\n",
    "print( f'Overall score: { scores[\"compound\"] }' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ana.polarity_scores(\"The novel isn't bad.\")\n",
    "print( f'Overall score: { scores[\"compound\"] }' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Vader also takes into account emoticon codes such as ':)'.  Without the emoticon, the positivity score for the sentence below is 0.23. With the added smiley code, the positivity score rises to 0.338. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ana.polarity_scores(\"It was the best of times, it was the worst of times. :) \")\n",
    "\n",
    "print( f'Positive: { scores[\"pos\"] }' )\n",
    "print( f'Negative: { scores[\"neg\"] }' )\n",
    "print( f'Compound: { scores[\"compound\"] }' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analyses of longer texts\n",
    "\n",
    "Vader's `polarity_scores()` methods can give good results for individual words, or for relatively shorts text. When the method is applied to longer texts (e.g. the full text of a novel), however, the scores quickly become meaningless. \n",
    "\n",
    "When you want to analyse the degree of positivity or negativity in a full novel, it is generally advisable to divide the text into its seperate sentences first, using the `sent_tokenize()` method from the `nltk` package, for instance. Once you have found the sentiment scores for all of these sentences individually, you can alo calculate the average of these scores.\n",
    "\n",
    "As a second approach, you can also consider the sentiment scores of individual words. We can count all the words with a positive score, and all the words with a negative score. When we then subtract the number of positive words from the number of negative words, this may also give an indication of the overall affective nature of the text. \n",
    "\n",
    "You can experiment with these two approaches in the exercises below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "\n",
    "C.J. Hutto Eric Gilbert, \"VADER: A Parsimonious Rule-based Model for\n",
    "Sentiment Analysis of Social Media Text\", in: *ICWSM 2014* <[https://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/paper/view/8109](https://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/paper/view/8109)>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Exercise 12.1\n",
    "\n",
    "Use the code below to download a file named 'ulysses_reviews.txt', available at [edu.nl/fyf8v](https://edu.nl/fyf8v)\n",
    "\n",
    "This file contains the full text of a number of reviews of James Joyce's novel *Ulysses* which were posted on the [goodReads](https://www.goodreads.com/book/show/338798.Ulysses) social reading platform. \n",
    "\n",
    "Can you select all the positive words from these reviews? Can you also select all the words with a negative connotation?\n",
    "Is the number of positive words higher than the number of than negative words?\n",
    "\n",
    "You can the steps below:\n",
    "\n",
    "1. Create two lists, named `positive_words` and `negative_words`.\n",
    "2. Tokenise the text file, and calculate the score for positivity and the score for negativity for each of these words. \n",
    "3. If the posiitivity score is higher than 0.75, append the word to the list named `positive_words`. If the negativitiy score is higher than 0.75, append the word to `negative_words`.\n",
    "4. Finally, you can subtract the length of the list `negative_words` from the length of the list `positive_words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get('http://edu.nl/fyf8v')\n",
    "if response:\n",
    "    response.encoding = 'utf-8'\n",
    "    with open( 'ulysses_reviews.txt' , 'w' , encoding = 'utf-8') as out:\n",
    "        out.write(response.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "reviews = open( 'ulysses_reviews.txt' , encoding = 'utf-8')\n",
    "\n",
    "positive_words = []\n",
    "negative_words = []\n",
    "\n",
    "for line in reviews:\n",
    "    words = word_tokenize(line)\n",
    "    for word in words:\n",
    "        scores = ana.polarity_scores(word)\n",
    "        if scores[\"pos\"] > 0.75:\n",
    "            positive_words.append(word)\n",
    "        elif scores[\"neg\"] > 0.75:\n",
    "            negative_words.append(word)\n",
    "        \n",
    "#print( positive_words) \n",
    "#print( negative_words) \n",
    "\n",
    "print( len(positive_words) )\n",
    "print( len(negative_words) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 12.2\n",
    "\n",
    "What is the most negative sentence in these reviews of *Ulysses*? What is the most positive sentence? \n",
    "\n",
    "Try to implement the following steps:\n",
    "    \n",
    "1. Create a dictionary named `sent_scores` which can save the scores. In this dictionary, you can use sentences as keys, and the compound scores as values.    \n",
    "1. Navigate across all the lines in the file. Each line of the file is the full text of single review. \n",
    "2. Tokenisise the reviews into sentences.\n",
    "4. Navigate across all the sentences in these reviews and save the compound scores for these sentences in the dictionary `sent_scores`.\n",
    "5. Sort the dictionary named `sent_scores` in a descending order, and print the first few items it contain. The postive sentences will be shown at the top of the list. To see the negative sentence, you need to sort the dictionary in a descending order. \n",
    "\n",
    "Unfortunately, there is no standard function in Python that you can use to sort a dictionary by its values. This specific task can be performed using the function `sortedByValue()`, defined below. This function can opionally be used with a parameter named `ascending`. If the value of this parameter is `False`, the values will be sorted in a descending order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortedByValue( dict , ascending = True ):\n",
    "    if ascending: \n",
    "        return {k: v for k, v in sorted(dict.items(), key=lambda item: item[1])}\n",
    "    else:\n",
    "        return {k: v for k, v in reversed( sorted(dict.items(), key=lambda item: item[1]))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "sent_scores = dict()\n",
    "\n",
    "file = open( 'Ulysses_reviews.txt' , encoding = 'utf-8')\n",
    "\n",
    "for review in file:\n",
    "    sentences = sent_tokenize(review)\n",
    "    for s in sentences:\n",
    "        scores = ana.polarity_scores(s)\n",
    "        sent_scores[s] = scores['compound']\n",
    "        \n",
    "nr_sentences = 10\n",
    "\n",
    "i = 0\n",
    "\n",
    "print('\\nPostive sentences\\n')\n",
    "\n",
    "for s in sortedByValue( sent_scores , ascending = False ):\n",
    "    print( f'{s} [{ sent_scores[s]}]' )\n",
    "    i+= 1\n",
    "    if i == nr_sentences:\n",
    "        break\n",
    "        \n",
    "print('\\nNegative sentences\\n')\n",
    "i = 0\n",
    "        \n",
    "for s in sortedByValue( sent_scores , ascending = True):\n",
    "    print( f'{s} [{ sent_scores[s]}]' )\n",
    "    i+= 1\n",
    "    if i == nr_sentences:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does *Ullyses* express more positivity than *Pride and Prejudice*? Try to answer this question by following the steps below:\n",
    "    \n",
    "1. Read in the full text of *Ullyses*\n",
    "2. Create an empty list, named for *all_scores* for instance, to capture all the scores. \n",
    "2. Divide the novel into its separate sentences.\n",
    "3. For each sentence, find the positive sentiment score. \n",
    "4. Add this score to the list *all_scores*.\n",
    "5. Once you have processed all the sentences, divide the sum of all the scores by by the total number of sentences. \n",
    "6. Follow steps 1-4 for the reviews *Pride and Prejudice*, and compare the two percentages you have calculated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "from os.path import join\n",
    "\n",
    "def average_score(file):\n",
    "    all_scores = []\n",
    "    file = open( file , encoding = 'utf-8' )\n",
    "    full_text = file.read()\n",
    "    sentences = sent_tokenize( full_text )\n",
    "    for s in sentences:\n",
    "        scores = ana.polarity_scores(s)\n",
    "        all_scores.append( scores[\"pos\"] )\n",
    "    return sum(all_scores) / len(all_scores)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
